{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/media/user/AI Models/Transformers_cache'\n",
    "# print(os.environ['TRANSFORMERS_CACHE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, torch\n",
    "# diffusers imports are weird, helper:\n",
    "# from diffusers import\n",
    "from diffusers.utils.export_utils import export_to_video\n",
    "from diffusers.pipelines.pipeline_utils import DiffusionPipeline\n",
    "from diffusers.schedulers.scheduling_dpmsolver_multistep import DPMSolverMultistepScheduler\n",
    "from diffusers.pipelines.text_to_video_synthesis.pipeline_text_to_video_synth_img2img import VideoToVideoSDPipeline\n",
    "from PIL import Image\n",
    "from diffusers.pipelines.text_to_video_synthesis.pipeline_text_to_video_synth import TextToVideoSDPipeline\n",
    "\n",
    "start = time.time()\n",
    "pipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "assert isinstance(pipe, TextToVideoSDPipeline)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()\n",
    "print(f\"Loaded model in {time.time() - start:.06}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate\n",
    "start = time.time()\n",
    "pos_prompt = open(\"input-pos.txt\", \"r\").read()\n",
    "neg_prompt = open(\"input-neg.txt\", \"r\").read()\n",
    "cfg = 7\n",
    "\n",
    "video_frames = pipe(pos_prompt, negative_prompt=neg_prompt, num_inference_steps=25, guidance_scale=cfg).frames # type: ignore\n",
    "fname = str(time.time()) + \".mp4\"\n",
    "video_path = export_to_video(video_frames, 'out/' + fname) # type: ignore\n",
    "print(\"Video saved to\", video_path)\n",
    "print(\"Time taken:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale\n",
    "start = time.time()\n",
    "pipe = DiffusionPipeline.from_pretrained(\"cerspense/zeroscope_v2_XL\", torch_dtype=torch.float16)\n",
    "assert isinstance(pipe, VideoToVideoSDPipeline)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# memory optimization\n",
    "pipe.unet.enable_forward_chunking(chunk_size=1, dim=1)\n",
    "pipe.enable_vae_slicing()\n",
    "\n",
    "video = [Image.fromarray(frame).resize((1024, 576)) for frame in video_frames]\n",
    "\n",
    "video_frames = pipe(pos_prompt, negative_prompt=neg_prompt, guidance_scale=cfg, video=video, strength=0.6).frames # type: ignore\n",
    "fname = fname.replace(\".mp4\", \"_upscale.mp4\")\n",
    "video_path = export_to_video(video_frames, 'out/' + fname) # type: ignore\n",
    "print(\"Video saved to\", video_path)\n",
    "print(\"Time taken:\", time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
