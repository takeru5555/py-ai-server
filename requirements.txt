accelerate == 0.25.0
autoawq
diffusers == 0.25.0
emoji == 2.9.0
fastapi == 0.108.0
gradio == 4.13.0
huggingface_hub
librosa
numpy >=  1.22.0
omegaconf == 2.3.0
pydantic == 2.5.3
pydantic_settings
python-dotenv == 1.0.0
python-magic
scipy == 1.11.4
simpleaudio == 1.0.4
sse_starlette
# styletts2 == 0.1.4
starlette_context
torch == 2.1
torchaudio == 2.1
TTS == 0.22.0
transformers == 4.36.2
uvicorn == 0.25.0

# https://github.com/turboderp/exllamav2/releases/download/v0.0.10/exllamav2-0.0.10+cu121-cp311-cp311-linux_x86_64.whl
https://github.com/turboderp/exllamav2/releases/download/v0.0.11/exllamav2-0.0.11+cu121-cp311-cp311-linux_x86_64.whl

# also `CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install llama-cpp-python`

git+https://github.com/m-bain/whisperx.git
