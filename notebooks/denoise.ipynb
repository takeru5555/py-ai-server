{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "# import disp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "input_file = '/path/to/media.wav'\n",
    "output_file = '/path/to/output.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "models = {}\n",
    "try:\n",
    "\tmodels['m1'] = whisperx.load_model(\n",
    "\t\t\t'large-v2',\n",
    "\t\t\tdevice='cuda',\n",
    "\t\t\tcompute_type='float16',\n",
    "\t\t\tlanguage='en'\n",
    "\t\t)\n",
    "except:\n",
    "\tprint('OOM?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "try:\n",
    "\tmodels['m2'] = whisperx.load_model(\n",
    "\t\t\t'large-v2',\n",
    "\t\t\tdevice='cuda',\n",
    "\t\t\tcompute_type='float16',\n",
    "\t\t\tlanguage='en'\n",
    "\t\t)\n",
    "except:\n",
    "\tprint('OOM?')\n",
    "\timport gc, torch\n",
    "\tdel models\n",
    "\tgc.collect()\n",
    "\ttorch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Mayavoz\n",
    "from mayavoz.models import Mayamodel\n",
    "\n",
    "model = Mayamodel.from_pretrained(\"shahules786/mayavoz-waveunet-valentini-28spk\")\n",
    "assert isinstance(model, Mayamodel)\n",
    "\n",
    "res = model.enhance(input_file) # type: ignore\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using resemble-enhance\n",
    "\n",
    "from resemble_enhance.enhancer.inference import denoise, enhance\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "path = input_file\n",
    "solver = 'euler'\n",
    "nfe = 50 # 1 to 128\n",
    "denoising = True\n",
    "lambd = 0.9 if denoising else 0.1\n",
    "tau = 0.5\n",
    "\n",
    "dwav, sr1 = torchaudio.load(path) # type: ignore\n",
    "orig_wav = dwav.cpu().numpy()\n",
    "dwav = dwav.mean(dim=0)\n",
    "print(sr1)\n",
    "\n",
    "wav1, sr2 = denoise(dwav, sr1, device)\n",
    "wav2, sr3 = enhance(dwav, sr1, device, nfe=nfe, solver=solver, lambd=lambd, tau=tau)\n",
    "\n",
    "# denoise works pretty well\n",
    "# enhance damaged speech in my first test (maybe use less steps)\n",
    "\n",
    "print(sr1, sr2, sr3)\n",
    "wav1 = wav1.cpu().numpy()\n",
    "wav2 = wav2.cpu().numpy()\n",
    "\n",
    "ipd.display(ipd.Audio(orig_wav, rate=sr1))\n",
    "ipd.display(ipd.Audio(wav1, rate=sr2))\n",
    "ipd.display(ipd.Audio(wav2, rate=sr3))\n",
    "\n",
    "# does denoiser take vram into account?\n",
    "# my usage goes up to 11.64/12GB\n",
    "\n",
    "# save denoised\n",
    "# torchaudio.save(output_file, torch.tensor(wav1), new_sr) # type: ignore\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
